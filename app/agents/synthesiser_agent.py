"""SynthesiserAgent â€“ compiles final markdown report.

Integrates text summaries, metrics, comparisons, critiques, and images
into a comprehensive markdown report using LLM-based synthesis.
"""

from __future__ import annotations

import datetime as dt
import logging
import os
import base64
from pathlib import Path
from typing import Any, List, Optional

import openai
import pandas as pd
from PIL import Image

from app.core import Artifact, Task, TaskStatus, TextPart
from app.utils.pdf_tools import extract_images_from_pdf

from .base import BaseAgent

logger = logging.getLogger(__name__)

DEFAULT_REPORT_TEMPLATE = """
# Research Report

**Generated by**: {agent_id}
**Timestamp**: {timestamp}

{summary_section}

{metrics_section}

{comparison_section}

{critique_section}

{images_section}
"""


SYSTEM_TEMPLATE = """
You are an expert scientific writer specializing in research paper analysis. 
Using the provided components, compose a clear, structured research report with the following sections:

1. Executive Summary: A concise overview of the paper's key contributions and findings
2. Key Metrics: Present the most important metrics in a clear format
3. Method Comparison: Analyze how different methods compare based on the metrics
4. Critical Analysis: Present balanced pros and cons of the claims
5. Visual Analysis: If images are available, analyze what they show and how they support the paper's findings
6. Conclusion: Synthesize the findings into actionable insights

Guidelines for high-quality analysis:
- Be specific and precise in your analysis, avoiding vague statements
- Critically evaluate the metrics and claims, noting any inconsistencies or limitations
- When discussing figures/images, explain their significance to the research findings
- Highlight practical implications of the research
- Use proper markdown formatting with headings, lists, and tables

If any component is missing, adapt your report accordingly while maintaining a professional tone.
"""


class SynthesiserAgent(BaseAgent):
    async def _handle(self, task: Task) -> None:  # noqa: D401
        if task.task_type != "Synthesise_Report":
            return

        template = self.config.get("report_template", DEFAULT_REPORT_TEMPLATE)
        logger.info(f"Synthesiser {self.agent_id} building smart report.")

        # ------------------------------------------------------------------
        # Gather components: from payload or filesystem (fallback)
        # ------------------------------------------------------------------

        def _load_json(path: Path):
            import json
            with path.open("r", encoding="utf-8") as f:
                return json.load(f)

        session_dir = Path("data/results") / task.session_id if task.session_id else Path("data/results")
        session_dir.mkdir(parents=True, exist_ok=True)

        summary = task.payload.get("summary")
        if not summary:
            for f in session_dir.glob("*_summary.json"):
                data = _load_json(f)
                summary = data["parts"][0]["text"]
                break

        metrics = task.payload.get("metrics")
        if not metrics:
            for f in session_dir.glob("*_metrics.json"):
                metrics = _load_json(f)
                break

        comparison = task.payload.get("comparison")
        if not comparison:
            for f in session_dir.glob("*_comparison.json"):
                comparison = _load_json(f)["parts"][0]["text"]
                break

        critiques = task.payload.get("critiques")
        if not critiques:
            for f in session_dir.glob("*_critique.json"):
                critiques = _load_json(f)["parts"][0]["data"]
                break

        # ------------------------------------------------------------------
        # Extract images from PDF if available
        # ------------------------------------------------------------------
        
        images: List[dict] = []
        pdf_path = task.payload.get("pdf_path")
        
        if pdf_path and Path(pdf_path).exists():
            try:
                logger.info(f"Extracting images from PDF: {pdf_path}")
                extracted_images = extract_images_from_pdf(pdf_path)
                
                # Save images to session directory
                for i, img_data in enumerate(extracted_images):
                    try:
                        img_path = session_dir / f"image_{i}.png"
                        with open(img_path, "wb") as f:
                            f.write(img_data)
                        
                        # Create a thumbnail and encode as base64 for markdown
                        img = Image.open(img_path)
                        img.thumbnail((400, 400))  # Resize for report
                        img_path_thumb = session_dir / f"image_{i}_thumb.png"
                        img.save(img_path_thumb)
                        
                        images.append({
                            "path": str(img_path),
                            "thumb_path": str(img_path_thumb),
                            "caption": f"Figure {i+1} extracted from the paper"
                        })
                    except Exception as img_exc:
                        logger.warning(f"Failed to process image {i}: {img_exc}")
                
                # Generate captions for images using LLM if summary is available
                if images and summary:
                    try:
                        # Create a client for image captioning
                        caption_client = openai.AsyncAzureOpenAI(
                            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
                            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
                            api_version="2025-01-01-preview",
                        )
                        
                        # Create a prompt that includes the summary and asks for image captions
                        caption_prompt = f"""
                        Based on this research paper summary:
                        
                        {summary}
                        
                        Please generate descriptive captions for {len(images)} figures extracted from the paper.
                        Each caption should explain what the figure likely represents in the context of the research.
                        Format your response as a numbered list (1., 2., etc.) with one caption per figure.
                        """
                        
                        caption_response = await caption_client.chat.completions.create(
                            model="gpt-4o-mini-2",
                            messages=[
                                {"role": "system", "content": "You are an expert at interpreting scientific figures and diagrams."},
                                {"role": "user", "content": caption_prompt},
                            ],
                            max_tokens=500,
                            temperature=0.3,
                        )
                        
                        caption_text = caption_response.choices[0].message.content.strip()
                        
                        # Extract captions from the response
                        import re
                        caption_matches = re.findall(r'^\d+\.\s+(.+)$', caption_text, re.MULTILINE)
                        
                        # Apply captions to images
                        for i, caption in enumerate(caption_matches):
                            if i < len(images):
                                images[i]["caption"] = caption
                        
                        logger.info(f"Generated {len(caption_matches)} captions for images")
                    except Exception as caption_exc:
                        logger.warning(f"Failed to generate image captions: {caption_exc}")
                
                logger.info(f"Extracted {len(images)} images from PDF")
            except Exception as exc:
                logger.exception(f"Failed to extract images: {exc}")

        # ------------------------------------------------------------------
        # Build prompt for LLM
        # ------------------------------------------------------------------

        prompt_parts: list[str] = []
        if summary:
            prompt_parts.append("### Summary\n" + summary)
        
        if metrics:
            metrics_text = ""
            try:
                df = pd.DataFrame(metrics)
                metrics_text = df.to_markdown(index=False)
            except Exception:
                metrics_text = str(metrics)
            prompt_parts.append("### Metrics\n" + metrics_text)
        
        if comparison:
            prompt_parts.append("### Comparison\n" + comparison)
        
        if critiques:
            critique_text = ""
            for i, critique in enumerate(critiques):
                claim = critique.get("claim", "")
                pros = "\n".join(f"- {p}" for p in critique.get("pros", []))
                cons = "\n".join(f"- {c}" for c in critique.get("cons", []))
                critique_text += f"Claim {i+1}: {claim}\n\nPros:\n{pros}\n\nCons:\n{cons}\n\n"
            prompt_parts.append("### Critique\n" + critique_text)
        
        if images:
            images_text = f"### Images\n{len(images)} figures were extracted from the paper:\n\n"
            for i, img in enumerate(images):
                images_text += f"Figure {i+1}: {img['caption']}\n"
            prompt_parts.append(images_text)

        user_prompt = "\n\n".join(prompt_parts)

        # ------------------------------------------------------------------
        # Query LLM (Azure OpenAI)
        # ------------------------------------------------------------------

        client = openai.AsyncAzureOpenAI(
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            api_version="2025-01-01-preview",
        )

        try:
            resp = await client.chat.completions.create(
                model="gpt-4o-mini-2",
                messages=[
                    {"role": "system", "content": SYSTEM_TEMPLATE},
                    {"role": "user", "content": user_prompt},
                ],
                max_tokens=1500,
                temperature=0.4,
            )
            llm_report = resp.choices[0].message.content.strip()
            
            # Add images to the report if available
            if images:
                image_section = "\n\n## Figures\n\n"
                for i, img in enumerate(images):
                    image_section += f"### Figure {i+1}\n\n"
                    # Convert backslashes to forward slashes for better compatibility
                    thumb_path = img['thumb_path'].replace('\\', '/')
                    image_section += f"![{img['caption']}]({thumb_path})\n\n"
                
                llm_report += "\n\n" + image_section
            
            report_md = llm_report
            
        except Exception as exc:  # pylint: disable=broad-except
            logger.exception("Synthesiser LLM failed: %s", exc)
            # Fallback: template concat as before
            timestamp = dt.datetime.utcnow().isoformat()
            
            summary_md = f"## Summary\n\n{summary}\n" if summary else ""
            
            metrics_md = ""
            if metrics:
                try:
                    df = pd.DataFrame(metrics)
                    metrics_md = "## Metrics\n\n" + df.to_markdown(index=False) + "\n"
                except Exception:
                    metrics_md = "## Metrics\n\n```" + str(metrics) + "\n```"
            
            comparison_md = f"## Method Comparison\n\n{comparison}\n" if comparison else ""
            
            critique_md = ""
            if critiques:
                critique_md = "## Critical Analysis\n\n"
                for i, critique in enumerate(critiques):
                    claim = critique.get("claim", "")
                    pros = "\n".join(f"- {p}" for p in critique.get("pros", []))
                    cons = "\n".join(f"- {c}" for c in critique.get("cons", []))
                    critique_md += f"### Claim {i+1}: {claim}\n\n**Pros:**\n{pros}\n\n**Cons:**\n{cons}\n\n"
            
            images_md = ""
            if images:
                images_md = "## Figures\n\n"
                for i, img in enumerate(images):
                    images_md += f"### Figure {i+1}\n\n"
                    # Convert backslashes to forward slashes for better compatibility
                    thumb_path = img['thumb_path'].replace('\\', '/')
                    images_md += f"![{img['caption']}]({thumb_path})\n\n"
            
            report_md = template.format(
                agent_id=self.agent_id,
                timestamp=timestamp,
                summary_section=summary_md,
                metrics_section=metrics_md,
                comparison_section=comparison_md,
                critique_section=critique_md,
                images_section=images_md,
            )

        # Save the report to the session directory
        report_path = session_dir / "final_report.md"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report_md)
        logger.info(f"Saved report to {report_path}")

        artifact = Artifact(name="report", parts=[TextPart(text=report_md)])
        task.status = TaskStatus.completed
        task.artifacts = [artifact]

        await self._emit_karma(self.agent_id, +1, reason="report-done")

        logger.info("%s produced final report with %d images", self.agent_id, len(images)) 